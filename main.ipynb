{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Analysis of available Data"]},{"cell_type":"markdown","metadata":{},"source":["Import required libraries"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: sounddevice in c:\\users\\as116\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from -r requirements.txt (line 1)) (0.4.3)Note: you may need to restart the kernel to use updated packages.\n","Requirement already satisfied: numpy in c:\\users\\as116\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from -r requirements.txt (line 2)) (1.20.3)\n","Requirement already satisfied: torchvision in c:\\users\\as116\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from -r requirements.txt (line 3)) (0.11.1)\n","Requirement already satisfied: torch in c:\\users\\as116\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from -r requirements.txt (line 4)) (1.10.0)\n","\n"]},{"name":"stderr","output_type":"stream","text":["ERROR: Could not find a version that satisfies the requirement zipfile (from versions: none)\n","ERROR: No matching distribution found for zipfile\n"]}],"source":["%pip install -r requirements.txt"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2983,"status":"ok","timestamp":1635797156013,"user":{"displayName":"Akash Pratap Singh","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12823741000222027042"},"user_tz":-330},"id":"oixc9tS-FbMM","outputId":"97a6677a-191b-4363-9b02-3894aa1b1586"},"outputs":[],"source":["import os\n","import numpy as np\n","from constant import *\n","from data_func import *\n","import matplotlib.pyplot as plt\n","import tensorflow.keras as keras\n","import keras.layers as layers\n","import tensorflow as tf\n","\n"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["os.chdir(rootPath)"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Extraction Finished.\n","Data loaded\n","Data shape :  (119,)\n"]},{"name":"stderr","output_type":"stream","text":["c:\\Users\\as116\\OneDrive - Indian Institute of Technology Bombay\\Documents B\\Sem 7\\IE643\\IE643_180260004_CHALLENGE\\data_func.py:32: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n","  data = np.array(data)\n"]}],"source":["raw_data,raw_labels,filenames, SAMPLE_RATE = load_files()\n","# print('raw data shape is ---',raw_data.shape)\n","import warnings\n","\n","warnings.filterwarnings(\"ignore\", category=np.VisibleDeprecationWarning) "]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["from audiomentations import Compose, AddGaussianNoise, TimeStretch, TimeMask, Shift,TimeStretch, Trim, Normalize\n","# import numpy as np\n","\n","\n","augment = Compose([\n","    Trim(top_db=20,p=1),\n","    AddGaussianNoise(min_amplitude=0.001, max_amplitude=0.015, p=0.5),\n","    TimeStretch(min_rate=0.8, max_rate=1.25, p=0.5),\n","    Shift(min_fraction=-0.5, max_fraction=0.5, p=0.5)\n","])"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["data shape--- (50, 119)\n","labels shape 119\n"]}],"source":["data_folds=[]\n","num_folds=50\n","for i in range(num_folds):\n","    data=[]\n","    for sound in raw_data:\n","        data.append(augment(sound,SAMPLE_RATE))\n","    data_folds.append(data)\n","\n","data_folds = np.array(data_folds)\n","# labels = np.array(raw_labels)\n","print('data shape---',data_folds.shape)\n","print('labels shape',len(raw_labels))    "]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["data=[]\n","labels=[]\n","for fold  in data_folds:\n","    for i,j in enumerate(fold):\n","        data.append(j)\n","        labels.append(raw_labels[i])\n","\n","# data = np.array(data, dtype=np.float64)\n","# labels = np.array(labels, dtype=np.float64)"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["stft_data = []\n","for i, sound in enumerate(data):\n","    stft = np.abs(librosa.stft(sound, n_fft=512, hop_length=256, win_length=512))\n","    stft = np.mean(stft, axis=1)\n","    stft_data.append(stft)\n","\n","stft_data = np.array(stft_data)\n"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["num_labels = len(labels_dir)\n","from sklearn.preprocessing import LabelBinarizer\n","one_hot = LabelBinarizer().fit(range(1,num_labels+1))\n","one_hot_labels = one_hot.transform(labels)"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["from sklearn.model_selection import train_test_split as split\n","\n","data_train, data_test, labels_train, labels_test = split(\n","    stft_data, one_hot_labels, train_size=0.6, shuffle=True, random_state=42\n",")\n","data_val, data_test, labels_val, labels_test = split(\n","    data_test, labels_test, train_size=0.5, shuffle=True, random_state=42\n",")\n"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["data train shape (3570, 257)\n","label train <class 'numpy.ndarray'> (3570, 7)\n"]}],"source":["print(\"data train shape\", data_train.shape)\n","print(\n","    \"label train {}\".format(type(labels_train)),\n","    len(labels_train) if type(labels_train) == \"list\" else labels_train.shape,\n",")"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":["#some error in trying to train the model using these datasets, couldn't figure out\n","\n","# train_dataset = tf.data.Dataset.from_tensor_slices((data_train,labels_train))\n","# val_dataset = tf.data.Dataset.from_tensor_slices((data_val,labels_val))"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[],"source":["model = keras.models.Sequential()\n","model.add(layers.Dense(256, activation=\"relu\", input_shape=(input_features,)))\n","\n","model.add(layers.Dense(256, activation=\"relu\"))\n","\n","model.add(layers.Dense(128, activation=\"relu\"))\n","\n","model.add(layers.Dense(128, activation=\"relu\"))\n","model.add(layers.Dropout(0.5))\n","model.add(layers.Dense(num_labels, activation=\"relu\"))\n","\n","model.compile(\n","    loss=keras.losses.CategoricalCrossentropy(from_logits=True),\n","    metrics=[\"accuracy\"],\n","    optimizer=\"adam\",\n",")\n"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Final datset shapes are\n","data train shape (3570, 257)\n","labels train shape (3570, 7)\n"]}],"source":["print('Final datset shapes are')\n","print('data train shape',data_train.shape)\n","print('labels train shape',labels_train.shape)"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/20\n","447/447 [==============================] - 6s 8ms/step - loss: 1.0507 - accuracy: 0.6465 - val_loss: 0.6965 - val_accuracy: 0.7807\n","Epoch 2/20\n","447/447 [==============================] - 3s 7ms/step - loss: 0.3705 - accuracy: 0.8885 - val_loss: 0.2822 - val_accuracy: 0.9025\n","Epoch 3/20\n","447/447 [==============================] - 4s 9ms/step - loss: 0.2235 - accuracy: 0.9317 - val_loss: 0.4077 - val_accuracy: 0.9034\n","Epoch 4/20\n","447/447 [==============================] - 3s 6ms/step - loss: 0.2243 - accuracy: 0.9398 - val_loss: 0.1111 - val_accuracy: 0.9672\n","Epoch 5/20\n","447/447 [==============================] - 4s 8ms/step - loss: 0.1206 - accuracy: 0.9667 - val_loss: 0.2326 - val_accuracy: 0.9176\n","Epoch 6/20\n","447/447 [==============================] - 3s 7ms/step - loss: 0.0861 - accuracy: 0.9754 - val_loss: 0.0444 - val_accuracy: 0.9882\n","Epoch 7/20\n","447/447 [==============================] - 3s 6ms/step - loss: 0.0692 - accuracy: 0.9818 - val_loss: 0.1342 - val_accuracy: 0.9790\n","Epoch 8/20\n","447/447 [==============================] - 3s 6ms/step - loss: 0.1010 - accuracy: 0.9773 - val_loss: 0.0883 - val_accuracy: 0.9798\n","Epoch 9/20\n","447/447 [==============================] - 3s 7ms/step - loss: 0.0476 - accuracy: 0.9885 - val_loss: 0.0040 - val_accuracy: 1.0000\n","Epoch 10/20\n","447/447 [==============================] - 4s 9ms/step - loss: 0.0811 - accuracy: 0.9773 - val_loss: 0.0942 - val_accuracy: 0.9714\n","Epoch 11/20\n","447/447 [==============================] - 4s 8ms/step - loss: 0.0287 - accuracy: 0.9910 - val_loss: 0.0078 - val_accuracy: 0.9966\n","Epoch 12/20\n","447/447 [==============================] - 4s 8ms/step - loss: 0.0328 - accuracy: 0.9913 - val_loss: 0.0046 - val_accuracy: 1.0000\n","Epoch 13/20\n","447/447 [==============================] - 4s 8ms/step - loss: 0.0220 - accuracy: 0.9952 - val_loss: 0.0024 - val_accuracy: 1.0000\n","Epoch 14/20\n","447/447 [==============================] - 3s 7ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.4056e-04 - val_accuracy: 1.0000\n","Epoch 15/20\n","447/447 [==============================] - 3s 8ms/step - loss: 3.9787e-04 - accuracy: 1.0000 - val_loss: 4.6213e-05 - val_accuracy: 1.0000\n","Epoch 16/20\n","447/447 [==============================] - 4s 9ms/step - loss: 2.1978e-04 - accuracy: 1.0000 - val_loss: 1.4980e-05 - val_accuracy: 1.0000\n","Epoch 17/20\n","447/447 [==============================] - 4s 8ms/step - loss: 0.2681 - accuracy: 0.9560 - val_loss: 0.0123 - val_accuracy: 0.9941\n","Epoch 18/20\n","447/447 [==============================] - 4s 8ms/step - loss: 0.0236 - accuracy: 0.9958 - val_loss: 0.3956 - val_accuracy: 0.9143\n","Epoch 19/20\n","447/447 [==============================] - 3s 8ms/step - loss: 0.0952 - accuracy: 0.9801 - val_loss: 0.0204 - val_accuracy: 0.9924\n","Epoch 20/20\n","447/447 [==============================] - 4s 9ms/step - loss: 0.0125 - accuracy: 0.9966 - val_loss: 3.0900e-04 - val_accuracy: 1.0000\n"]},{"data":{"text/plain":["<keras.callbacks.History at 0x241a4f32d60>"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["model.fit(data_train,labels_train,batch_size=8,epochs=20,validation_data=(data_val,labels_val))"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["38/38 [==============================] - 0s 6ms/step - loss: 4.0663e-04 - accuracy: 1.0000\n"]},{"data":{"text/plain":["[0.0004066294350195676, 1.0]"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["model.evaluate(data_test,labels_test)"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyMhWxjfPxdXy8hwltHFWe3h","mount_file_id":"1E0bemQUHH52L150IhXeW8lfc33XEi7hv","name":"IE643_180260004_CHALLENGE_CODE.ipynb","provenance":[]},"interpreter":{"hash":"35f6d45b7a1ee2f3dfd6026ab6a59891378e324129b14532f05a55490eaa27f2"},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.9"}},"nbformat":4,"nbformat_minor":2}
